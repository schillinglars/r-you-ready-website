---
title: "1 RStudio"
format: html
---

Fragen zu RStudio

Unabhängig von konkreten Fragen zu RStudio kannst du [hier](https://methodenlehre.github.io/einfuehrung-in-R/) noch mal das Skript zur Einführung in R Studio von Andrew Ellis und Boris Mayer abrufen.

## Was gibt es alles für Funktionen zum Einlesen der Daten und welche davon ist am besten geeignet?

Der einfachste Weg die Daten zu laden, geht über das Environment oben rechts in RStudio. Welche Funktion benötigt wird bzw. welche Funktion verwenden werden kann hängt vom Dateiformat der zu ladende Datei ab. Häufig verwendete Dateiformate sind *.xlsx*, *.csv* und *.sav*. Bei *.csv* handelt es sich um eine Textdatei, bei welcher die Spalten durch Kommas (csv = Comma-separated values) oder Semikolons getrennt sind. *.sav* ist die Dateiendung für eine SPSS-Datei und *.xlsx* ist die Dateiendung für eine Excel-Datei.

::: {.callout-note}
Weiterführende Informationen und Beispiele können [hier](https://methodenlehre.github.io/einfuehrung-in-R/chapters/03-data_frames.html#daten-importieren) nachgelesen werden.
:::

![Abb. 1.: Environment](images/screenshot_environment.png)

## Wofür stehen die zusätzlichen Argumente wie `escape_double` oder `trim_ws` beim Einlesen von Dateien?

::: {.callout-important}
Du kannst anhand der Syntax `?Funktionsname()`die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.
:::

Wenn man mit `read_delim()` aus dem `readr` Paket die Daten einliest, interpretiert das Argument `escape_double = TRUE` doppelte Anführungsstriche als einfache Anführungsstriche (““ = “). Mit dem Argument `trim_ws = TRUE` werden Leerzeichen vor oder nach einer Zeichenkette gelöscht („ Vor dem „V“ befindet sich ein Leerzeichen = „Vor dem „V“ befindet sich ein Leerzeichen). Beide Optionen sind per Default auf TRUE gesetzt. Die folgenden beiden Varianten sind somit identisch:

```{r}
#| echo: true
#| eval: false

data <- readr::read_delim("data.csv", delim = ";", escape_double = TRUE, trim_ws = TRUE)

data <- readr::read_delim("data.csv", delim = ";")
```


## Was ist der Unterschied zwischen `cbind()` und den `xy_join()`-Funktionen?

Die Funktion `cbind()` kann man sich wie „Kleber“ vorstellen. Die Datensätze werden ohne Berücksichtigung der Reihenfolgen der Zeilen aneinandergeklebt. Hierdurch könnten im zusammengefügten Datensatz Werte derselben Zeile von verschiedenen Versuchspersonen stammen. Mit der Funktion `xy_join()` wird vor dem Zusammenfügen der beiden Datensätze die Reihenfolge der Zeilen über beide Datensätze hinweg kontrolliert und angeglichen. Hierfür wird jene Spalte verwendet, die im Argument `xy_join(data, by = „…“)` genannt wurde. Damit wird sichergestellt, dass im resultierenden Datensatz Werte derselben Zeile auch von einer einzelnen Versuchsperson stammen.

## Was ist der Unterschied zwischen `inner_join()`, `left_join()`, `right_join()`, `full_join()`?

Die Funktionen unterscheiden sich dahingehend, was von den beiden Datensätzen nach der Zusammenfügung erhalten bleiben soll. `inner_join()` übernimmt nur Zeilen, welche in beiden Datensätzen vorhanden sind. `full_join()` übernimmt alle Zeilen, auch wenn sie nur in einen der beiden Datensätze auftaucht. Der Eintrag in der Spalte des anderen Datensatzes wird einfach mit *NA* ergänzt. Die verbleibenden beiden Funktionen "bevorzugen" sozusagen ihren entsprechenden Datensatz, übernehmen von diesem alle Zeilen und vom anderen Datensatz lediglich die damit übereinstimmenden.

::: {.callout-note}
Eine ausführlichere Beschreibung zu dem Thema findet sich auch noch mal [hier](https://r4ds.hadley.nz/joins.html#how-do-joins-work) unter Kapitel 19.4. [Hier](https://psu-psychology.github.io/r-bootcamp-2019/talks/joins_tutorial_bnj.html#mutating_joins:_inner,_left,_right,_full) sind animierte Abbildungen zu den Funktionsweisen.
:::

## Wann verwendet man welche der `xy_join()`-Funktionen und anhand welcher Variable sollen die Datensätze zusammengefügt werden?

Welche der `xy_join()`-Funktionen man am sinnvollsten nutzen sollte hängt von der Datenstruktur ab und was man mit den Daten im Folgenden noch machen möchte. Ein Datensatz mit `full_join()` erstellt würde beispielsweise die meisten Einträge (inkl. NAs) aufweisen, andererseits wäre dieser Datensatz aber auch vermutlich am unübersichtlichsten. Ob man `right_join()` oder `left_join()` verwendet kann beispielsweise einfach nur davon abhängen, welchen Datensatz man als links (bzw. zuerst) vorliegend oder als rechts (bzw. als zweites) vorliegend definiert. Das hängt von den Argumenten in der Funktion ab. Kurzum: Welche Funktion am passendsten ist hängt von der spezifischen Fragestellung ab und davon, in welcher Reihenfolge man die Datensätze betrachtet und der Funktion übergeben möchte. Anhand welcher Variable die Zusammenfügung der Datensätze erfolgen soll lässt sich ebenfalls nicht pauschal sagen. Jeder Datensatz kann andere Spaltennamen oder Strukturen aufweisen. In der Psychologie ist es allerdings üblich, dass man jeder Versuchsperson über Datenerhebungen hinweg einen individuellen Code zuweist. Dieser wird dann zum Zusammenfügen verwendet. Oft heisst diese Variable *Code* oder *ID* – sie kann aber auch komplett anders heissen. Unabhängig vom konkreten Namen sollte das Codebook anzeigen, ob es eine solche Variable gibt und um welche es sich handelt.

## Wie kann man ein bereits gesetztes working directory (also den Arbeitsspeicher des Skriptes) verschieben, idealerweise sogar von ausserhalb eines Projektes in ein Projekt hinein?

Am einfachsten schliesst man das Skript und verschiebt es innerhalb deines Ordnersystems in das Projekt. Dann öffnet man RStudio (aber nicht das Skript, sondern nur das Programm) und wählt im gestarteten RStudio über *File – Open File…* das Skript aus und speichert es ab. Das working directory sollte nun innerhalb des Projektes liegen.

## Was ist der Unterschied zwischen der Funktion `mutate()` und der Funktion `summarize()`? Wie kombiniert man diese Funktionen am besten mit `group_by()`?

::: {.callout-important}
Vorweg: Du kannst anhand der Syntax `?Funktionsname()`die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.
:::

Mit `mutate()` fügst du Spalten hinzu oder änderst sie, während alle Zeilen erhalten bleiben; `summarise()` verdichtet hingegen die Zeilen zu Aggregaten – ohne Gruppierung zu **einer Zeile für den gesamten Datensatz** und mit `group_by()` zu **einer Zeile pro Gruppe** – und gibt dabei nur die Gruppenvariablen sowie die neu berechneten Kennwerte zurück.

::: {.callout-note}
Visualisierungen finden sich [hier](https://www.andrewheiss.com/blog/2024/04/04/group_by-summarize-ungroup-animations/#mutating-within-groups).
:::

## Wie funktioniert die Umwandlung eines wide-Datensatzes hin zu einem long-Datensatz und welche Argumente beinhaltet die hierfür angewendete Funktion `pivot_longer()`?

::: {.callout-important}
Du kannst anhand der Syntax `?Funktionsname()`die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.
:::

Wie schon in der Frage erwähnt, die passende Funktion zur Umwandlung eines Datensatzes vom wide-Format in das long-Format erfolgt anhand der Funktion `pivot_longer()`. Die Funktion nimmt als die ersten beiden Argumente den Datensatz (`data`) und die Spalten, welche transformiert werden sollen (`cols`). Mit den anderen beiden Argumenten werden die Namen bestimmt, welche die Spalten haben sollen, in welcher die früheren Spaltenüberschriften (`names_to = "name"`) und die Werte (`values_to = "value"`) eingetragen werden.

```{r}
#| echo: true
#| eval: false

data_long <- data_wide |> 
  pivot_longer(
    cols = c(Spalte1, Spalte2, Spalte3), 
    names_to = "Hier kommt der Name der Spalte rein, in welcher die früheren Spaltenüberschriften abgelegt sind", 
    values_to = "Hier kommt der Name der Spalte rein, in welcher die Werte der entsprechenden früheren Spalten abgelegt sind"
  )

```

::: {.callout-note}
Weitere Informationen und Beispiele finden sich [hier](https://methodenlehre.github.io/einfuehrung-in-R/chapters/04-tidyverse.html).
:::

## Wie funktioniert der Pipe Operator `|>` bzw. `%>%` und was ist der Unterschied zwischen den beiden?

Der Pipe Operator nimmt das Resultat von oben bzw. links und übergibt dieses Zwischenergebnis nach unten bzw. rechts. Was helfen könnte: Die Syntax erst ohne Pipe aufschreiben und dann die Klammern nach und nach auflösen und mit der Pipe ersetzen. Die folgenden Code-Snippets sind äquivalent:

```{r}
#| echo: true
#| eval: false

summarize(
  filter(data, Variable == "A"),
  mean = mean(Wert, na.rm = TRUE),
  sd = sd(Wert, na.rm = TRUE)
)

data %>%
  filter(Variable == "A") %>%
  summarize(mean = mean(Wert, na.rm = TRUE), sd = sd(Wert, na.rm = TRUE))

data |> 
  filter(Variable == "A") |> 
  summarize(mean = mean(Wert, na.rm = TRUE), sd = sd(Wert, na.rm = TRUE))

```

::: {.callout-note}
Die Pipe Operatoren unterscheiden sich nur geringfügig und die Unterschiede sind für den Rahmen des Seminars nicht relevant, können jedoch [hier](https://r4ds.hadley.nz/data-transform.html#sec-the-pipe) nachgelesen werden.
:::

## Wie funktioniert die `t.test()`-Funktion?

::: {.callout-important}
Du kannst anhand der Syntax `?Funktionsname()`die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.
:::

Bei der `t.test()`-Funktion werden die Mittelwerte von Gruppen verglichen. Das Argument `x` ist verpflichtend und erwartet einen nummerischen Vektor (üblicherweise der Wert von Versuchspersonen auf der relevanten Variable). Das Argument `y` ist ein optionaler weiterer nummerischer Vektor, falls es sich um einen Zwei-Stichproben-Tests handelt. Das Argument `alternative` spezifiziert wie der t-Test ausgerichtet ist (≤, ≥ oder ≠). Das Argument `mu` gibt den erwarteten Mittelwert unter H0 an (Default = 0). Das Argument `var.equal` bestimmt, ob der Test unter der Annahme von Varianzhomogenität durch wird. Sprich, ob zwischen den beiden Gruppen die Varianzen gleich sind. Ist diese Annahme erfüllt, so wird ein students t-Test gerechnet. Ansonsten wird ein Welch t-Test gerechnet. Mit `conf.level` kann das Konfidenzintervall beliebig angepasst werden (Default = 0.95). Hier ein Beispiel Code-Snippet:

```{r}
#| echo: true
#| eval: false

t.test(x = data$Wert[data$Gruppe == "A"], 
       y = data$Wert[data$Gruppe == "B"], 
       alternative = "two.sided", # in diesem Fall ist der Test ungerichtet
       mu = 0, # H0: Mittelwertunterschied = 0 (Default)
       var.equal = FALSE, # Ablehnung der Varianzhomogenität (Defualt) und damit ein Welch`s t-Test
       conf.level = 0.95) # Default
```


## Was ist der Unterschied zwischen `as_factor()` und `as.factor()`?

::: {.callout-important}
Du kannst anhand der Syntax `?Funktionsname()`die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt. Hierüber lassen sich auch Unterschiede zwischen ähnlichen Funktionen feststellen.
:::

Beide Funktionen formatieren Werte einer Spalte hin zu Faktoren. `as.factor()` ist in Base R vorhanden und erstellt die Faktoren anhand des Alphabets. `as_factor()` stammt aus dem Tidyverse, kann bereits in SPSS-Dateien enthaltene Faktorisierungen auslesen und erstellt neue Faktoren anhand der Auftrittsreihenfolge im Vektor.

## Was gibt es bei ggplot alles für Visualisierungsmöglichkeiten?

Mit ggplot kann eine ganze Reihe an Visualisierungen manuell festgelegt werden, von der Art des Graphen, mehrdimensionale Darstellungen, Formatierung wie Farben, Grössen uvm. Eine grobe Übersicht gibt es [hier](https://rstudio.github.io/cheatsheets/html/data-visualization.html).

::: {.callout-note}
Beispiele und Übungen finden sich [hier](https://r4ds.hadley.nz/data-visualize.html).
:::

## Wie kann man sicherstellen, dass bei der Visualisierung von Graphen die APA-Guidelines eingehalten werden?

Hierfür gibt es ein extra `[theme_apa()](https://rdrr.io/cran/jtools/man/theme_apa.html)`. Dieses nimmt einem viele der Formatierungen ab. Einzelheiten muss man trotzdem noch prüfen bzw. je nach Abbildung müssen manche Formatierungen auch noch selbst ergänzt werden. Die genaueren APA-Guidelines sind auch noch mal [hier](https://apastyle.apa.org/style-grammar-guidelines/tables-figures/figures) zu finden.

## Wann wird ein Element mit und wann wird ein Element ohne Anführungszeichen angesprochen?

Als Regel: Spricht man ein Objekt aus der Environment an, dann werden *keine* Anführungszeichen verwendet. Spricht man numerische Elemente aus einer Spalte an, dann werden ebenfalls *keine* Anführungszeichen verwendet. Spricht man Spaltenelemente an, welche als Faktor oder als Character formatiert sind, dann werden auch Anführungszeichen verwendet.

## Wie funktionieren die relativen Pfade und wie stellt man sicher, dass diese auch bei fremden Personen funktionieren?

Relative Pfade gehen immer vom working directory (Arbeitsspeicher des Skripts) aus. Wenn man also Daten laden möchtest, dann muss man immer schauen, wo sich – ausgehend vom working directory – die Datenfiles befindet. Bei der Syntax des dann angegebenen Pfades gilt folgendes: 1. "Datensatz.Dateiendung" bildet ausnahmslos das Ende des Pfades. 2. "/" bilden den nächsten Step, also den Übergang von einem Ordner zum nächsten oder vom finalen Ordner zur Datei. 3. Soll im Ordnersystem in einen Ordner auf einer Ebene weiter oben gewechselt werden, dann kann ein "." zusätzlich verwendet werden. Hier ein beispielhaftes Code-Snipet:

```{r}
#| echo: true
#| eval: false

data <- readr::read_csv("../data/Datensatz.Dateiendung") # Starte im working directory (deswegen der erste ".") und gehe eine Ordnerebene hoch (deswegen der zweite "."). Von dort aus gehe in den Ordner "data" und wähle dort die Datei "Datensatz" aus, welche dem Format "Dateiendung" entspricht.
```

Wird einer fremden Person nun das gesamte Ordnersystem mit all seinen Inhalten unverändert übergeben, so kann der Dateipfad innerhalb dieses Ordnersystems immer auch den Datensatz einlesen.

![Abb. 2.: Dateipfade](images/dateipfade.png)

## Wann wird die Tilde (~) und das Dollarzeichen `($)` verwendet?

Die Tilde bedeutet, was links von ihr steht, wird von dem, was rechts von ihr steht, vorhergesagt. Beispielsweise wird die Tilde üblicherweise bei Regressionen verwendet: `lm(AV ~ UV).` Das Dollarzeichen dient vor allem, um Spalten anhand ihrer Namen anzusprechen: `data$Spaltenname`. Manche Funktionen arbeiten mit beiden Schreibweisen. Beispielsweise sind die folgenden Schreibweisen äquivalent:

```{r}
#| echo: true
#| eval: false

t.test(data$variable1, data$variable2)
      
t.test(data, formula = variable ~ group)
```

Allerdings müssen bei letzterer Schreibweise die Werte beider Gruppen zwingend im selben Datensatz vorliegen.

## Wann wird die Tilde (~) verwendet und wann wird ein Komma (`,`) verwendet?

Die Tilde bedeutet, was links von ihr steht, wird von dem, was rechts von ihr steht, vorhergesagt. Beispielsweise wird die Tilde üblicherweise bei Regressionen verwendet: `lm(AV ~ UV)`. Das Komma wird verwendet, um Argumente in einer Funktion zu trennen. Beispiel:

```{r}
#| echo: true
#| eval: false

result <- lm(AV ~ UV, data = datensatz)

result <- t.test(x = datensatz$variable1, y = datensatz$variable2)
```


::: {.callout-warning}
Das Komma sollte **nicht** verwendet werden um Dezimalzahlen zu definieren! Dies führt zu einer Fehlermeldung. Für Dezimalzahlen wird immer der Punkt verwendet (z.B. 3.14).
:::

## Wie berechnet man das generalisierte η²?

Man erhält das generalisierte η² indem man erst eine ANOVA berechnet, abspeichert und dann über `summary(anova_ergebnis, es = ges)` ausgeben lässt.

```{r}
#| echo: true
#| eval: false

anova_ergebnis <- afex::aov_car(value ~ treatment, data = example_data)

summary(anova_ergebnis, es = ges)
```


## Wie bereitet man die Daten für eine mixed-ANOVA vor?

Eine mixed-ANOVA besteht aus der Varianzerklärung aufgrund unterschiedlicher Gruppenzugehörigkeiten (bspw. Kontrollgruppe und Experimentalgruppe) und einer Messwiederholung (mehrerer Messwerte pro Person, unabhängig von der Gruppenzugehörigkeit). Beides muss auch bereits in den Daten erkennbar sein. Sprich, pro Versuchsperson muss anhand einer Variable codiert sein, zu welcher Gruppe diese Versuchsperson gehört. Darüber hinaus muss es für jede Versuchsperson zu jedem Messzeitpunkt einen Wert geben. Angenommen die Daten liegen ursprünglich im wide-Format vor, dann müssen diese erst ins long-Format übertragen werden (siehe auch Fragen zum long-Format). Erst dann können die entsprechenden ANOVA-Funktionen die Daten entsprechend interpretieren.

::: {.callout-note}
Inhalte zu ANOVAs mit Messwiederholung oder mixed-ANOVAs könnt ihr auch noch mal über die Inhalte aus [Statistik IV von Boris Mayer und Stefan Thoma](https://methodenlehre.github.io/statistik-IV/) wiederholen
:::

## Wofür gibt es bei der Funktion `aov_4()` das Argument `(1 | Personenidentifikationscode)`. bzw. das Argument `(Wiederholungsfaktor | Personenidentifikationscode)`?

::: {.callout-important}
Du kannst anhand der Syntax `?Funktionsname()`die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.
:::

Die Funktion `aov_4()` ist auf ANOVAs mit Messwiederholung ausgelegt und erwartet die zusätzliche Syntax `(x | y)`. Die genaue Formulierung dieses Arguments hängt dann davon ab, ob es **keine Messwiederholung gibt** `(1 | Personenidentifikationscode)` oder ob es **eine Messwiederholung** gibt `(Wiederholungsfaktor | Personenidentifikationscode)`.

```{r}
#| echo: true
#| eval: false

afex::aov_4(value ~ treatment + (1 | Personenidentifikationscode), data = example_data) # Beispiel ohne(!) Messwiederholung

afex::aov_4(value ~ treatment + (time | Personenidentifikationscode), data = example_data) # Beispiel mit(!) Messwiederholung
```


::: {.callout-note}
Für die Funktion `aov_4()` gibt es aus [Statistik-IV von Boris Mayer und Stefan Thoma](https://methodenlehre.github.io/statistik-IV/) noch tiefere und beispielhafte Ausführungen.
:::

## Wie stellt man ein, dass in Markdown oder Quarto der Output meines Codes unterbunden wird?

Es kann entweder im ersten Chunk des Dokuments als globale Einstellung `knitr::opts_chunk$set(output = FALSE)` oder im entsprechend gewünschten Chunk einzeln die Option `{r, output = FALSE}` gesetzt werden den Output zu unterdrücken. Mittlerweile können solche Optionen auch über die Schreibweise `#|` explizit innerhalb des Chunks geschrieben werden. Ähnliche Befehle existieren auch, wenn man stattdessen oder zusätzlich Warnmeldungen oder den Code unterbinden möchte. Stellt bei der Endabgabe aber bitte sicher, dass der Code und mögliche Warnmeldungen sichtbar sind!

```{r}
# Hierdurch würde der Code zwar angezeigt, aber nicht mehr durchgeführt werden
# #| eval: FALSE
# Hierdurch würde der Code dann zusätzlich auch nicht mehr angezeigt werden
# #| echo: FALSE
```


## Was bedeutet die Meldung „summarise() has grouped output by 'group'. You can override using the .groups argument.“ und was muss ich dabei beachten?

Üblicherweise werden deskriptive Werte (auch) für Subgruppen der Gesamtstichprobe angegeben (beispielsweise getrennt für Männer und Frauen, für die Kontrollgruppe oder die Experimentalgruppe etc.). Um entsprechende Änderungen vorzunehmen, wird daher vor der Anwendung von `summarise()` noch die Funktion `group_by()` verwendet. Nach der Berechnung der Deskriptivstatistik wird die Gruppierung nicht aufgehoben. Sie bleibt im Hintergrund, nicht direkt sichtbar, erhalten. Die Warnmeldung weisst genau darauf hin. Möchte man die Gruppierung aufheben, dann kann entweder die Funktion `ungroup()` verwendet werden oder `summarise()` wird um das Argument `summarise(.group = „drop)` ergänzt. Gruppierungen aufzulösen kann für manche Vorgänge, wie beispielsweise das Löschen von noch gruppierten Spalten relevant sein.

## Wann soll eine neue Variable bzw. ein neuer Datensatz erstellt werden und wann soll die alte Variable bzw. der neue Datensatz überspeichert werden?

Grundsätzlich ist es vorzuziehen neue Variablen oder Datensätze zu erstellen. Zum einen kann so bei Bedarf noch auf die ursprünglichen Variablen oder Datensätze zugegriffen werden. Zum anderen ist die Analyse so für aussenstehende leichter nachzuvollziehen. Ausnahmen sind ästhetische Änderungen oder wiederholte Berechnungen, welche für die weitere Analyse nicht weiter relevant sind.

## Wann eignet es sich ein Projekt anzulegen?

Ein Projekt anzulegen, lohnt sich vor allem dann, wenn in mehreren Skripten gearbeitet wird. Dann muss nicht in jedem Skript einzeln das working directory (Arbeitsspeicher des Skripts) gesetzt werden. Wird in nur einem Skript gearbeitet, dann macht das Anlegen des Projekts keinen Unterschied.
